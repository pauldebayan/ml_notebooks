{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "780c6bf5-66db-4b12-a849-871828ba10df",
   "metadata": {},
   "source": [
    "## Mapping "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad19f8-8d93-4be7-9a74-708ed895f218",
   "metadata": {},
   "source": [
    "## Generate Numbers with a GAN\n",
    "\n",
    "# GAN Image\n",
    "\n",
    "Here Z is a noise vector - random numbers<br/>\n",
    "Here Y is the probability - The value of Y will be compared to 1 and Re-Train\n",
    "\n",
    "\n",
    "\n",
    "## 1 - Value of Real Image, 0 - Value of Fake Image\n",
    "\n",
    "In Discriminator both Fake and Real image will be provided and Y will be compared for both Fake vs Fake Label(0) and Real vs Real Label(1) - re-Train - BackPropagation - automatically done by PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e4f201-532f-45c9-a2e3-97474736ce84",
   "metadata": {},
   "source": [
    "## Cross Entropy\n",
    "\n",
    "[Cross Entropy](https://www.youtube.com/watch?v=FODwUM-1PyI)\n",
    "\n",
    "[Expected Value](https://www.youtube.com/watch?v=KLs_7b7SKi4)\n",
    "\n",
    "For Information Theory we use Log\n",
    "\n",
    "How to use Cross Entropy Function\n",
    "Example - a person travelling in Titanic - Survived - 1 or Died - 0\n",
    "\n",
    "\n",
    "Wanted Probability - p(x) = [1, 0] - That actually happened<br/>\n",
    "Actual Probability - q(x) = [0.4, 0.6] - Generated by the model we will use Cross Entropy to calculate how far it is from the Wanted Probability<br/>\n",
    "\n",
    "\n",
    "<!-- $$ H(p, q) = -\\sum_{i=1}^{n} p(x) * log q(x)$$ -->\n",
    "\n",
    "$$ H(p, q) = -\\sum p(x) * log q(x)$$ \n",
    "\n",
    "\n",
    "H = -[1*ln(0.4)+0*ln(0.6)] = 0.91, more the value - more far from the wanted probability\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "678a9d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deb/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import the libraries\n",
    "import torch, pdb # Here pdb is the library to do debugging in Python \n",
    "# Dataloader will be able to iterate through the training data as we train the network\n",
    "from torch.utils.data import DataLoader # Dataloader is a library of pytorch\n",
    "from torch import nn # nn is part of Pytorch library that helps us build very quickly deep learning architectures and models\n",
    "#transforms will allow us to transform out training data in different ways\n",
    "from torchvision import  transforms# torchvision is for the computer vision\n",
    "from torchvision.datasets import MNIST\n",
    "#We will build a grid of images to evaluate during the training - how the fake images created by the generator\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "#library to create a beautiful progressbar as you are training\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd026ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function - to display as we are training \n",
    "# - agreed with the number of generated images versus the real images\n",
    "\n",
    "# Here ch = 1 is channel (grayscale)\n",
    "# size = (28, 28) size of the MNIST dataset\n",
    "# num = number of images we want to show - grid of 4x4 or 5x5\n",
    "# Visualization function\n",
    "def show(tensor, ch=1, size=(28, 28), num=16):\n",
    "    #tensor: 128x784\n",
    "    # when using backpropagation in pytorch, gradients are being calculated when they are linked to different\n",
    "    # variables - we want to just visualize whats contained in that variable - don't want any processing to take place \n",
    "    # with a gradient. detach that variable from the computation of gradients\n",
    "    # size = 28x28 - reshaping that we are doing\n",
    "    # tensor = 128 x 784 - we will process 128 images at a time, 784 = 28x28\n",
    "    # The tensor that we will be managing during the training - is going to have this dimensions -  128 x 784\n",
    "    # ch will be 1\n",
    "    # whatever remains will be the first dimension\n",
    "    data = tensor.detach().cpu().view(-1, ch, *size) # 128 x 1 x 28 x 28\n",
    "    # We want cpu only for the visualization\n",
    "    # result of this operation is going to transform this 128x784 dimensional tensor into a -\n",
    "    # 128 x 1 x 28 x 28, size = 28, ch = 1, whatever remains -1\n",
    "\n",
    "    # We are going to take the first 16 elements of the above multidimensional tensor that has 128\n",
    "    # From that 128 we are goint to take 16\n",
    "    # The second parameter - number of rows we want to set\n",
    "    # nrows - 16 pictures - sq. grid -4 rows x 4 columns \n",
    "    # permute is a function that allows us to change the order of the channels - order of the dimension\n",
    "    \n",
    "    grid = make_grid(data[:num], nrows=4).permute(1, 2, 0) # pytorch - channel(C), width(W), height(H) nut matplotlib WHC (1, 2, 0) are indeces > 28x28x1\n",
    "    \n",
    "    # Why? The first computation will give [16 x 1 x 28 x 28]\n",
    "    # we will get a series of images that have this internal structure - [16 x 1 x 28 x 28]\n",
    "    # But if we want to display these with matplotlib the author of the channel has to be different pytorch uses\n",
    "    # channel with width and height - but we want matplotlib - to have width, height and channel - so change the order of the channels\n",
    "\n",
    "    \n",
    "\n",
    "    plt.imshow(grid)\n",
    "    plt.show()\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d89679",
   "metadata": {},
   "source": [
    "## What we have dane since now:\n",
    "1. We imported the libnraries\n",
    "2. We created the visualization function - to see later the content of the image created by generated during the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e04fb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup of main parameters and hyperparameters \n",
    "epochs = 500 # no. of cycles we are going to perform during the training \n",
    "cur_step = 0 # In each of the steps of the training we are going to process 1 batch - 1 set of images\n",
    "info_step = 300# This is going to store every how many steps we want to show in the screen information about the current LOSS values\n",
    "# We need to show the generator loss and discriminator loss\n",
    "\n",
    "mean_gen_loss = 0\n",
    "mean_disc_loss = 0\n",
    "\n",
    "#Hyper parameters\n",
    "z_dim = 50 # dimensionality of the noise vector, input of the generator\n",
    "# value can be anything what will be the dimentionality  of the latent space that we are going to learn\n",
    "lr = 0.00001 # learning rate, we will use adam optimizer\n",
    "loss_func = nn.BCEWithLogitsLoss() # Binary Cross entropy\n",
    "# 1. set the values 0 to 1; 2. After then Binary Cross Entropy\n",
    "# It is going to take the output of the neural network that are the logists and than \n",
    "# that function is going to apply all at once a sigmoid function\n",
    "# BCELoss vs BCEWithLogitsLoss - convert the numerical values to the range that goes from 0 to 1\n",
    "\n",
    "\n",
    "bs = 128 #batch size = during each step of the training how many images are going to process at once in the GPU.\n",
    "# Great adv. of GPU is that we can send a number of images in parallel to be processed by the GPU \n",
    "\n",
    "\n",
    "device = 'cuda' # Device where we are going to process the data\n",
    "\n",
    "dataloader = DataLoader(MNIST('.', download=True, transform=transforms.ToTensor())) # Hold our training data - give us back a bunch of training data containing \n",
    "# input elements for a network and a set of labels for those elements\n",
    "# . stor it in root\n",
    "# Transform the MNIST to a multi-dimensional tensor\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
