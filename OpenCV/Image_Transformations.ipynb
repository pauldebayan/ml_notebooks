{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec65e85f-91e8-4ca0-90db-a3df10c3a0fe",
   "metadata": {},
   "source": [
    "## Image Transformations:\n",
    "### 1. Translation\n",
    "### 2. Rotation\n",
    "### 3. Resizing\n",
    "### 4. Flipping\n",
    "### 5. Cropping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d14b0e7-3c75-4021-898b-6a92e799b629",
   "metadata": {},
   "source": [
    "## Translation\n",
    "\n",
    "![Translation](./images/nb_translation.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e844371-018f-4093-953a-cefa3c5081ef",
   "metadata": {},
   "source": [
    "We will use wrapAlline for translation - (img, M, dsize), M is the translation matrix, dsize means the number of colums and number of rows of the image\n",
    "\n",
    "## Translation Matrix\n",
    "\n",
    "![Translation Matrix](./images/nb_translation_matrix.jpg)\n",
    "\n",
    "OpenCV expects the Matrix to be floating point type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7128894a-046c-468d-a9f5-ed2f17f0eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df627914-8039-4505-bb47-3c78974c3b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./images/flemingo.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2351fb00-155a-45b3-b50e-6122f519219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(window_name, file_name):\n",
    "    cv2.imshow(window_name, file_name)\n",
    "    cv2.waitKey(5000)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38e0fcf5-fc7d-4914-9aa3-6788436afde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display('Bird', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c6744d5-8556-49e8-b38a-fd2c70ec85c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   0., 100.],\n",
       "       [  0.,   1., 150.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image Translation\n",
    "# Step 1 - We need to define our 'M' - float type\n",
    "tx, ty = 100, 150\n",
    "\n",
    "M = np.float32([[1, 0, tx],\n",
    "            [0, 1, ty]])\n",
    "\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e10cce3-07a9-44e9-98d1-395745e7e949",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_image = cv2.warpAffine(img, M, (img.shape[1], img.shape[0])) # img.shape[1] - number of columns\n",
    "display('Translated Image', translated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9550c9dd-a69c-4765-9079-52ea5e0b8ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translation(image, tx, ty):\n",
    "    M = np.float32([[1, 0, tx],\n",
    "                    [0, 1, ty]])\n",
    "    translated_image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "    display('Translated Image', translated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2473e69c-934f-44a6-bf5c-55c38a166550",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation(img, 100, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934d8dfa-b74c-4dae-b530-98dde486b33b",
   "metadata": {},
   "source": [
    "## Rotation\n",
    "## Negative value - clockwise and Positive value - anti-clockwise\n",
    "\n",
    "## Rotation Matrix\n",
    "![Rotation Matrix](./images/nb_rotation_matrix.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecf746e-a5a5-4367-ae1d-51e6b7e42fdb",
   "metadata": {},
   "source": [
    "We can use cv2.getRotationMatrix2D - we need to provide **Theta, cx and cy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79ecb4e7-07bd-4e7b-a89e-a7209c870e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display('Bird', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efd4d2f3-9bc5-46cb-84d0-70fce43e9760",
   "metadata": {},
   "outputs": [],
   "source": [
    "center = (img.shape[1]//2, img.shape[0]//2) # cols/2, rows/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f417d6bb-d7ad-4558-9459-c91c2c2a0288",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = cv2.getRotationMatrix2D(center, 45, 1) #center, angle and scale, 45 anti-clockwise, 1 is scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f387e12-372b-4661-b109-6a6751cbbc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.70710678,   0.70710678, -82.84271247],\n",
       "       [ -0.70710678,   0.70710678, 200.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e126dc79-0ea1-4955-ac8b-8d4f30316b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate_45 = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "251827fa-2cd8-4e01-af40-c14fc4efa74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display('Rotate 45 degree', rotate_45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20fa837a-3a27-4c60-99fc-69ea8fdf643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(image, angle, scale):\n",
    "    center = (image.shape[1]//2, image.shape[0]//2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "\n",
    "    rotate_image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    display('Rotate', rotate_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "871b550f-7695-48b4-8182-a9f0c22227e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate(img, -45, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3d5ebe-3922-459d-9090-bb396cbd0e6c",
   "metadata": {},
   "source": [
    "## Resizing\n",
    "## cv2.resize(img, dsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f03daa32-2b02-4483-a856-2a4f0d84e907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 400, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "976111c9-6454-41d6-9106-d1719262f322",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_resize = cv2.resize(img, (200, 200), interpolation=cv2.INTER_AREA)# interpolation - wants to shrink - INTER_AREA or enlarge - INTER_LINEAR the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "28c6e9fa-0881-4f22-b0ff-f9edb9099723",
   "metadata": {},
   "outputs": [],
   "source": [
    "display('Image Shrinked', img_resize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab2233b-2697-4e03-a803-6cec0d96950e",
   "metadata": {},
   "source": [
    "## Flipping\n",
    "\n",
    "## cv2.flip(img, flipCode)\n",
    "\n",
    "## flipCode \n",
    "- 1  - flip horizontally <br/>\n",
    "- -1  - flip vertically<br/>\n",
    "-  0 - flib both vertically and horizontally<br/>  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aa81cda5-d3f0-4023-b545-bef3e806edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_img = cv2.flip(img, 0) # 1, -1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fc9c5c74-5fed-4a70-abfd-396978be3415",
   "metadata": {},
   "outputs": [],
   "source": [
    "display('Flipped Image', flip_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3174f6fe-9db2-48a1-8597-1a69567da034",
   "metadata": {},
   "source": [
    "## Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "82104c7e-e9cb-49c7-bdb7-827593776014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 400, 3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "71289bb2-80b8-4396-9e2d-50fba0ff4ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = img[100:200, 100:200]# rows, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8aa1094d-372e-4dd6-9711-99b7bf877961",
   "metadata": {},
   "outputs": [],
   "source": [
    "display('Cropped', crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce00b6c8-2dcd-4dd6-a832-7cc55b55303c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
